{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework2 s278221.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9QcGnGPdX2C",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9O3aM3Tb28q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61
        },
        "outputId": "36e07ec6-bc1a-41fc-fed7-df1742cc65c9"
      },
      "source": [
        "!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm' "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo942LMOdlh4",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DokFOdD1dJEl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ffecc62-47bb-4cbd-fc5a-9a1d7701cb61"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import copy\n",
        "import pandas as pd\n",
        "\n",
        "# Visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4, 5, 6, [1], [2], [3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIDLJuIXK_vh",
        "colab_type": "text"
      },
      "source": [
        "**Set Arguments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5PkYfqfK_SA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
        "\n",
        "NUM_CLASSES = 101    # 101 + 1: There is am extra Background class that should be removed \n",
        "\n",
        "BATCH_SIZE = 128\n",
        "#BATCH_SIZE = 256     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = 1e-2            # The initial Learning Rate (di quanto mi sposto nella curva. LR piccolo->sposto molto)\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default \n",
        "\n",
        "NUM_EPOCHS = 30      # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 20       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gwii0TBHvzh",
        "colab_type": "text"
      },
      "source": [
        "**Define Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUDdw4j2H0Mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define transforms for training phase\n",
        "train_transform = transforms.Compose([transforms.Resize(256),      # Resizes short size of the PIL image to 256\n",
        "                                      transforms.CenterCrop(224),  # Crops a central square patch of the image\n",
        "                                                                   # 224 because torchvision's AlexNet needs a 224x224 input!\n",
        "                                                                   # Remember this when applying different transformations, otherwise you get an error\n",
        "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # Normalizes tensor with mean and standard deviation of ImageNet\n",
        "                                      #transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "])\n",
        "# Define transforms for the evaluation phase\n",
        "eval_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      #transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                                                                         \n",
        "])\n",
        "\n",
        "# Define transforms for training set ONLY.\n",
        "augmentation_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                              transforms.CenterCrop(224),\n",
        "                                              #transforms.RandomRotation(degrees=15),\n",
        "                                              #transforms.ColorJitter(),\n",
        "                                              transforms.Grayscale(num_output_channels=3),\n",
        "                                              transforms.RandomHorizontalFlip(),\n",
        "                                              transforms.ToTensor(),\n",
        "                                              transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])                                 \n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qYIHPzYLY7i",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfVq_uDHLbsR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a97dd2ee-a76c-4f77-86ef-a16fc1a8f2b4"
      },
      "source": [
        "#import shutil\n",
        "#shutil.rmtree('./Caltech101', ignore_errors=True)\n",
        "\n",
        "# Clone github repository with data\n",
        "if not os.path.isdir('./Caltech101'):\n",
        "  !git clone https://github.com/lindaludovisi/ellelle.git\n",
        "  !mv 'ellelle' 'Caltech101'\n",
        "\n",
        "\n",
        "DATA_DIR = 'Caltech101/101_ObjectCategories' #ObjectCategories is the directory containing all images\n",
        "from Caltech101.caltech_dataset import Caltech #Caltech is a class in caltech_dataset.py\n",
        "\n",
        "\n",
        "# Prepare Pytorch train/test Datasets\n",
        "train_dataset = Caltech(DATA_DIR, split='train',  transform=train_transform)\n",
        "test_dataset = Caltech(DATA_DIR, split='test', transform=eval_transform)\n",
        "\n",
        "\n",
        "#Create a list of all the indexes of the original train dataset\n",
        "original_indexes=list(range(len(train_dataset)))\n",
        "\n",
        "train_indexes = []\n",
        "val_indexes = []\n",
        "#Divide train dataset into train/val\n",
        "#The idea here is to assign indexes divisible by 2 to val_dataset and the others to train_dataset\n",
        "#The proportion between categories is maintained because the dataset is sorted by alphabetical order\n",
        "for index in original_indexes:\n",
        "  if ( (index %2) == 0) :  \n",
        "    val_indexes.append(index)\n",
        "  else:                    \n",
        "    train_indexes.append(index)\n",
        "\n",
        "val_dataset = Subset(train_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "\n",
        "#Perform data augmentation for train_dataset\n",
        "#train_dataset.dataset.transform = augmentation_transform\n",
        "\n",
        "# Check dataset sizes\n",
        "print('Train Dataset: {}'.format(len(train_dataset)))\n",
        "print('Valid Dataset: {}'.format(len(val_dataset)))\n",
        "print('Test Dataset: {}'.format(len(test_dataset)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of indexes is:\n",
            "5784\n",
            "length of labels is:\n",
            "5784\n",
            "length of indexes is:\n",
            "2893\n",
            "length of labels is:\n",
            "2893\n",
            "Train Dataset: 2892\n",
            "Valid Dataset: 2892\n",
            "Test Dataset: 2893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYEDQ7Z21ldN",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VriRw8SI1nle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbZ1t5Qs2z4j",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Prepare Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exHUjtXa22DN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "36ad0f3e-7f7f-41c3-b467-912990086d38"
      },
      "source": [
        "#A useful function that sets the parameters of the model to be updated in training phase.\n",
        "#When we are finetuning we can leave all of the .requires_grad’s set to the default of True.\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "  \n",
        "  if feature_extracting == 'conv':  #Freeze conv layers\n",
        "    for name, param in model.named_parameters(): \n",
        "      if 'features' in name :\n",
        "        param.requires_grad = False\n",
        "  \n",
        "  elif feature_extracting == 'fc':  #Freeze fc layers\n",
        "    for name, param in model.named_parameters(): \n",
        "      if 'classifier' in name :\n",
        "        param.requires_grad = False\n",
        "        print(name)\n",
        "      \n",
        "  else:\n",
        "    return True\n",
        "\n",
        "\n",
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "  # Initialize these variables which will be set in this if statement. Each of these\n",
        "  # variables is model specific.\n",
        "  model_ft = None\n",
        "  input_size = 0\n",
        "\n",
        "  if model_name == \"vgg\":\n",
        "    \"\"\" VGG11_bn\n",
        "    \"\"\"\n",
        "    model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(model_ft, feature_extract)\n",
        "    num_ftrs = model_ft.classifier[6].in_features  \n",
        "    model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
        "    input_size = 224\n",
        "\n",
        "  elif model_name == \"alexnet\":\n",
        "    \"\"\" Alexnet\n",
        "    \"\"\"\n",
        "    model_ft = models.alexnet(pretrained=use_pretrained)  \n",
        "    num_ftrs = model_ft.classifier[6].in_features\n",
        "    model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)  # nn.Linear in pytorch is a fully connected layer\n",
        "                                                              # The convolutional layer is nn.Conv2d\n",
        "    set_parameter_requires_grad(model_ft, feature_extract) \n",
        "    input_size = 224 \n",
        "\n",
        "  return model_ft, input_size\n",
        "\n",
        "\n",
        "# Loading AlexNet model (not pre-trained)\n",
        "#net, input_size = initialize_model(\"alexnet\", NUM_CLASSES, False, use_pretrained=False)\n",
        "\n",
        "# Loading AlexNet pre-trained model\n",
        "#net, input_size = initialize_model(\"alexnet\", NUM_CLASSES, feature_extract=False, use_pretrained=True)\n",
        "\n",
        "# Loading AlexNet pre-trained model, freezing conv layers\n",
        "#net, input_size = initialize_model(\"alexnet\", NUM_CLASSES, feature_extract='conv', use_pretrained=True)\n",
        "\n",
        "# Loading AlexNet pre-trained model, freezing fc layers\n",
        "#net, input_size = initialize_model(\"alexnet\", NUM_CLASSES, feature_extract='fc', use_pretrained=True)\n",
        "\n",
        "# Loading VGG pre-trained model, freezing conv layers\n",
        "net, input_size = initialize_model(\"vgg\", NUM_CLASSES, feature_extract='conv', use_pretrained=True)\n",
        "\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(net)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=101, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEyL3H_R4qCf",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sjq00G94tSc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4f4717df-6c6b-46e5-c364-121737d2eb97"
      },
      "source": [
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy\n",
        "\n",
        "\n",
        "# Choose parameters to optimize\n",
        " \n",
        "#parameters_to_optimize = net.parameters() # In this case we optimize over all the parameters of AlexNet\n",
        "\n",
        "parameters_to_optimize = []\n",
        "print(\"Params to learn:\")\n",
        "for name, param in net.named_parameters():\n",
        "  if param.requires_grad == True:\n",
        "    parameters_to_optimize.append(param)\n",
        "    print(\"\\t\",name)\n",
        "\n",
        "\n",
        "# Define optimizer\n",
        "# An optimizer updates the weights based on loss\n",
        "\n",
        "# We use SGD with momentum\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "#We also try to use Adam optimizer\n",
        "#optimizer = optim.Adam(parameters_to_optimize, lr=LR, weight_decay=WEIGHT_DECAY )\n",
        "\n",
        "\n",
        "# Define scheduler\n",
        "# A scheduler dynamically changes learning rate\n",
        "# The most common schedule is the step(-down), which multiplies learning rate by gamma every STEP_SIZE epochs\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t classifier.0.weight\n",
            "\t classifier.0.bias\n",
            "\t classifier.3.weight\n",
            "\t classifier.3.bias\n",
            "\t classifier.6.weight\n",
            "\t classifier.6.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxYUli9d9uYQ",
        "colab_type": "text"
      },
      "source": [
        "**Train and Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcoQ5fD49yT_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "18695b6d-2693-4bcd-ff6a-d1f5648604d4"
      },
      "source": [
        "# By default, everything is loaded to cpu\n",
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "cudnn.benchmark # Calling this optimizes runtime\n",
        "\n",
        "history = []\n",
        "val_acc_history = []\n",
        "best_acc = 0\n",
        "current_step = 0\n",
        "# Start iterating over the epochs\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_lr()))\n",
        "\n",
        "  # keep track of training and validation loss each epoch\n",
        "  train_loss = 0.0\n",
        "  valid_loss = 0.0\n",
        "\n",
        "  #\n",
        "  #   TRAINING\n",
        "  #\n",
        "\n",
        "  # Iterate over the dataset\n",
        "  for images, labels in train_dataloader:\n",
        "    # Bring data over the device of choice\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    net.train() # Sets module in training mode\n",
        "\n",
        "    # Clear the gradients\n",
        "    optimizer.zero_grad() \n",
        "\n",
        "    # Forward pass to the network\n",
        "    outputs = net(images)\n",
        "\n",
        "    # Compute loss based on output and ground truth\n",
        "    loss = criterion(outputs, labels)\n",
        "    # Backpropagation of gradients\n",
        "    loss.backward()\n",
        "    \n",
        "    # Update the weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # Track train loss by multiplying average loss by number of examples in batch\n",
        "    train_loss += loss.item() * images.size(0)   \n",
        "\n",
        "    # Log loss\n",
        "    if current_step % LOG_FREQUENCY == 0:\n",
        "      print('Step {}, Train Loss {}'.format(current_step, loss.item()))    \n",
        "\n",
        "    current_step += 1\n",
        "\n",
        "  # Step the scheduler\n",
        "  scheduler.step() \n",
        "\n",
        "  \n",
        "  #\n",
        "  #   VALIDATION\n",
        "  #\n",
        "  \n",
        "  net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "  net.train(False) # Set Network to evaluation mode\n",
        "\n",
        "  running_corrects = 0\n",
        "  for images, labels in tqdm(val_dataloader):\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    # Forward Pass \n",
        "    outputs = net(images)\n",
        "\n",
        "    # Validation loss\n",
        "    loss = criterion(outputs, labels)\n",
        "    # Multiply average loss times the number of examples in batch\n",
        "    valid_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # Get predictions from the maximum value\n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Update Corrects\n",
        "    running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  accuracy = running_corrects / float(len(val_dataset))\n",
        "\n",
        "  print('Validation Accuracy: {}'.format(accuracy))\n",
        "\n",
        "  # Append the value of the accuracy to the list\n",
        "  val_acc_history.append(accuracy)\n",
        "\n",
        "  #Save the model with the best accuracy\n",
        "  if (accuracy > best_acc):\n",
        "    best_acc = accuracy\n",
        "    best_net = copy.deepcopy(net.state_dict())\n",
        "\n",
        "  # Calculate average losses\n",
        "  train_loss = train_loss / len(train_dataloader.dataset)\n",
        "  valid_loss = valid_loss / len(val_dataloader.dataset)\n",
        "  \n",
        "  #Save train and validation loss\n",
        "  history.append([train_loss, valid_loss])\n",
        "\n",
        "#at the end, load best model weights\n",
        "net.load_state_dict(best_net)\n",
        "\n",
        "print(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1/30, LR = [0.01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 0, Train Loss 4.724756717681885\n",
            "Step 10, Train Loss 3.1337056159973145\n",
            "Step 20, Train Loss 1.8064237833023071\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:16<00:00,  1.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6815352697095436\n",
            "Starting epoch 2/30, LR = [0.01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 30, Train Loss 0.9746464490890503\n",
            "Step 40, Train Loss 0.8334675431251526\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:17<00:00,  1.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8226141078838174\n",
            "Starting epoch 3/30, LR = [0.01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 50, Train Loss 0.2855660915374756\n",
            "Step 60, Train Loss 0.32820913195610046\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:17<00:00,  1.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8744813278008299\n",
            "Starting epoch 4/30, LR = [0.01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 70, Train Loss 0.18816398084163666\n",
            "Step 80, Train Loss 0.24895380437374115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:16<00:00,  1.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8893499308437067\n",
            "Starting epoch 5/30, LR = [0.01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 90, Train Loss 0.1308072954416275\n",
            "Step 100, Train Loss 0.09955336153507233\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:16<00:00,  1.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9017980636237898\n",
            "Starting epoch 6/30, LR = [0.01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 110, Train Loss 0.12357963621616364\n",
            "Step 120, Train Loss 0.10496903210878372\n",
            "Step 130, Train Loss 0.08349767327308655\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:16<00:00,  1.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8973029045643154\n",
            "Starting epoch 7/30, LR = [0.01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 140, Train Loss 0.10405560582876205\n",
            "Step 150, Train Loss 0.0645449161529541\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:16<00:00,  1.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8959197786998617\n",
            "Starting epoch 8/30, LR = [0.01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 160, Train Loss 0.07201628386974335\n",
            "Step 170, Train Loss 0.05472686514258385\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:17<00:00,  1.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.90283540802213\n",
            "Starting epoch 9/30, LR = [0.01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 180, Train Loss 0.03439709171652794\n",
            "Step 190, Train Loss 0.043426599353551865\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:16<00:00,  1.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.90283540802213\n",
            "Starting epoch 10/30, LR = [0.01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 200, Train Loss 0.035425424575805664\n",
            "Step 210, Train Loss 0.03232996538281441\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:17<00:00,  1.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.901106500691563\n",
            "Starting epoch 11/30, LR = [0.01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 220, Train Loss 0.02445216104388237\n",
            "Step 230, Train Loss 0.032623082399368286\n",
            "Step 240, Train Loss 0.029521971940994263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:16<00:00,  1.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9024896265560166\n",
            "Starting epoch 12/30, LR = [0.01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 250, Train Loss 0.019544485956430435\n",
            "Step 260, Train Loss 0.017520722001791\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:17<00:00,  1.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9042185338865837\n",
            "Starting epoch 13/30, LR = [0.01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 270, Train Loss 0.010319150984287262\n",
            "Step 280, Train Loss 0.021345045417547226\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:16<00:00,  1.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9052558782849239\n",
            "Starting epoch 14/30, LR = [0.01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 290, Train Loss 0.036681924015283585\n",
            "Step 300, Train Loss 0.03560984134674072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:16<00:00,  1.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.90283540802213\n",
            "Starting epoch 15/30, LR = [0.01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 310, Train Loss 0.0174192413687706\n",
            "Step 320, Train Loss 0.016693636775016785\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:16<00:00,  1.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9062932226832642\n",
            "Starting epoch 16/30, LR = [0.01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 330, Train Loss 0.00932147353887558\n",
            "Step 340, Train Loss 0.01674903929233551\n",
            "Step 350, Train Loss 0.013995856046676636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:16<00:00,  1.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9017980636237898\n",
            "Starting epoch 17/30, LR = [0.01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 360, Train Loss 0.017019860446453094\n",
            "Step 370, Train Loss 0.01213109865784645\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:17<00:00,  1.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9042185338865837\n",
            "Starting epoch 18/30, LR = [0.01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 380, Train Loss 0.012623138725757599\n",
            "Step 390, Train Loss 0.010163988918066025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:17<00:00,  1.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.906984785615491\n",
            "Starting epoch 19/30, LR = [0.01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 400, Train Loss 0.016659490764141083\n",
            "Step 410, Train Loss 0.015193216502666473\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:16<00:00,  1.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9049100968188105\n",
            "Starting epoch 20/30, LR = [0.01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 420, Train Loss 0.024349704384803772\n",
            "Step 430, Train Loss 0.013141341507434845\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:17<00:00,  1.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9035269709543569\n",
            "Starting epoch 21/30, LR = [0.0001]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 440, Train Loss 0.01595243066549301\n",
            "Step 450, Train Loss 0.008102141320705414\n",
            "Step 460, Train Loss 0.012112066149711609\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:16<00:00,  1.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9045643153526971\n",
            "Starting epoch 22/30, LR = [0.001]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 470, Train Loss 0.008548833429813385\n",
            "Step 480, Train Loss 0.006575748324394226\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:17<00:00,  1.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9059474412171508\n",
            "Starting epoch 23/30, LR = [0.001]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 490, Train Loss 0.020385369658470154\n",
            "Step 500, Train Loss 0.00827217847108841\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:16<00:00,  1.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9083679114799447\n",
            "Starting epoch 24/30, LR = [0.001]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 510, Train Loss 0.008645020425319672\n",
            "Step 520, Train Loss 0.00961083173751831\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:16<00:00,  1.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.906984785615491\n",
            "Starting epoch 25/30, LR = [0.001]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 530, Train Loss 0.02181941270828247\n",
            "Step 540, Train Loss 0.006456382572650909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:16<00:00,  1.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9076763485477178\n",
            "Starting epoch 26/30, LR = [0.001]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 550, Train Loss 0.006537377834320068\n",
            "Step 560, Train Loss 0.012598700821399689\n",
            "Step 570, Train Loss 0.009956590831279755\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:16<00:00,  1.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9080221300138313\n",
            "Starting epoch 27/30, LR = [0.001]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 580, Train Loss 0.0332220159471035\n",
            "Step 590, Train Loss 0.011608093976974487\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:17<00:00,  1.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.906984785615491\n",
            "Starting epoch 28/30, LR = [0.001]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 600, Train Loss 0.010443419218063354\n",
            "Step 610, Train Loss 0.011068552732467651\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:16<00:00,  1.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9080221300138313\n",
            "Starting epoch 29/30, LR = [0.001]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 620, Train Loss 0.014083527028560638\n",
            "Step 630, Train Loss 0.005973242223262787\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:16<00:00,  1.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9059474412171508\n",
            "Starting epoch 30/30, LR = [0.001]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 640, Train Loss 0.010570354759693146\n",
            "Step 650, Train Loss 0.008274972438812256\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:16<00:00,  1.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.906984785615491\n",
            "[[2.939170093457234, 1.6005027000669951], [0.9414171348139129, 0.6758304173191224], [0.3784500771043706, 0.4682001368468563], [0.2166313228105938, 0.4143969931048476], [0.13540428373988403, 0.38385434805275165], [0.09709327976073796, 0.38913214874465435], [0.07597489574638146, 0.37534316990880057], [0.05336306451267227, 0.36419897043193855], [0.046686112303621706, 0.36130611035833715], [0.0372139377053183, 0.361721616562966], [0.03110334388447995, 0.35628194820501663], [0.02945302515438813, 0.35142035487611595], [0.023906132822049935, 0.35379260547593094], [0.02452323364189222, 0.355348292310538], [0.022156505663859894, 0.353738310920747], [0.02116788258031526, 0.3589809231078806], [0.017117605994186297, 0.35583200073835763], [0.02071179459863349, 0.3486350955310204], [0.014484826130161312, 0.34808064166605884], [0.011882026495610366, 0.3534890482534511], [0.012741737510818333, 0.35480156841779315], [0.012604320527442099, 0.3513040809710491], [0.01463046443248026, 0.34926496007135793], [0.012235761018544641, 0.34793557706875095], [0.011874656294721125, 0.34744295778775774], [0.010628550049345193, 0.347706266870802], [0.011777781187086514, 0.34833486751237186], [0.012022139620484158, 0.3467245441584501], [0.010328402987489396, 0.3472815018306959], [0.01052273490452008, 0.3471375833243585]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsHFI-GAJd69",
        "colab_type": "text"
      },
      "source": [
        "**Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO3HV5pqJg1o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2b8b0d02-8c29-456d-a5cb-9362abe1e287"
      },
      "source": [
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "net.train(False) # Set Network to evaluation mode\n",
        "\n",
        "running_corrects = 0\n",
        "for images, labels in tqdm(val_dataloader):\n",
        "#for images, labels in val_dataloader:\n",
        "  images = images.to(DEVICE)\n",
        "  labels = labels.to(DEVICE)\n",
        "\n",
        "  # Forward Pass in order to get logits/output\n",
        "  outputs = net(images)\n",
        "\n",
        "  # Get predictions from the maximum value\n",
        "  _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "  # Update Corrects\n",
        "  running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = running_corrects / float(len(val_dataset))\n",
        "\n",
        "print('Validation Accuracy performed on the best model: {}'.format(accuracy))\n",
        "\n",
        "\n",
        "# History is a Dataframe\n",
        "history = pd.DataFrame( history, columns=['train_loss', 'valid_loss'])\n",
        "\n",
        "# Plot train_loss vs valid_loss\n",
        "plt.figure(figsize=(8, 6))\n",
        "for c in ['train_loss', 'valid_loss']:\n",
        "  plt.plot(history[c], label=c)\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Average Loss')\n",
        "plt.title(f'Training and Validation Losses using SGD optimizer, LR={LR}, epochs={NUM_EPOCHS}')\n",
        "\n",
        "from torchsummary import summary\n",
        "summary(\n",
        "        net, input_size=(3, 224, 224), batch_size=BATCH_SIZE, device='cuda')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:16<00:00,  1.36it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy performed on the best model: 0.9083679114799447\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1        [128, 64, 224, 224]           1,792\n",
            "       BatchNorm2d-2        [128, 64, 224, 224]             128\n",
            "              ReLU-3        [128, 64, 224, 224]               0\n",
            "         MaxPool2d-4        [128, 64, 112, 112]               0\n",
            "            Conv2d-5       [128, 128, 112, 112]          73,856\n",
            "       BatchNorm2d-6       [128, 128, 112, 112]             256\n",
            "              ReLU-7       [128, 128, 112, 112]               0\n",
            "         MaxPool2d-8         [128, 128, 56, 56]               0\n",
            "            Conv2d-9         [128, 256, 56, 56]         295,168\n",
            "      BatchNorm2d-10         [128, 256, 56, 56]             512\n",
            "             ReLU-11         [128, 256, 56, 56]               0\n",
            "           Conv2d-12         [128, 256, 56, 56]         590,080\n",
            "      BatchNorm2d-13         [128, 256, 56, 56]             512\n",
            "             ReLU-14         [128, 256, 56, 56]               0\n",
            "        MaxPool2d-15         [128, 256, 28, 28]               0\n",
            "           Conv2d-16         [128, 512, 28, 28]       1,180,160\n",
            "      BatchNorm2d-17         [128, 512, 28, 28]           1,024\n",
            "             ReLU-18         [128, 512, 28, 28]               0\n",
            "           Conv2d-19         [128, 512, 28, 28]       2,359,808\n",
            "      BatchNorm2d-20         [128, 512, 28, 28]           1,024\n",
            "             ReLU-21         [128, 512, 28, 28]               0\n",
            "        MaxPool2d-22         [128, 512, 14, 14]               0\n",
            "           Conv2d-23         [128, 512, 14, 14]       2,359,808\n",
            "      BatchNorm2d-24         [128, 512, 14, 14]           1,024\n",
            "             ReLU-25         [128, 512, 14, 14]               0\n",
            "           Conv2d-26         [128, 512, 14, 14]       2,359,808\n",
            "      BatchNorm2d-27         [128, 512, 14, 14]           1,024\n",
            "             ReLU-28         [128, 512, 14, 14]               0\n",
            "        MaxPool2d-29           [128, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-30           [128, 512, 7, 7]               0\n",
            "           Linear-31                [128, 4096]     102,764,544\n",
            "             ReLU-32                [128, 4096]               0\n",
            "          Dropout-33                [128, 4096]               0\n",
            "           Linear-34                [128, 4096]      16,781,312\n",
            "             ReLU-35                [128, 4096]               0\n",
            "          Dropout-36                [128, 4096]               0\n",
            "           Linear-37                 [128, 101]         413,797\n",
            "================================================================\n",
            "Total params: 129,185,637\n",
            "Trainable params: 119,959,653\n",
            "Non-trainable params: 9,225,984\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 73.50\n",
            "Forward/backward pass size (MB): 23299.10\n",
            "Params size (MB): 492.80\n",
            "Estimated Total Size (MB): 23865.40\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxekmR745ySe",
        "colab_type": "text"
      },
      "source": [
        "**Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSHcUqLB5yWO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0806aa27-4e4b-41e2-a6b2-9df337ac412e"
      },
      "source": [
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "net.train(False) # Set Network to evaluation mode\n",
        "\n",
        "running_corrects = 0\n",
        "for images, labels in tqdm(test_dataloader):\n",
        "  images = images.to(DEVICE)\n",
        "  labels = labels.to(DEVICE)\n",
        "\n",
        "  # Forward Pass\n",
        "  outputs = net(images)\n",
        "\n",
        "  # Get predictions\n",
        "  _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "  # Update Corrects\n",
        "  running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = running_corrects / float(len(test_dataset))\n",
        "\n",
        "print('Test Accuracy: {}'.format(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [00:17<00:00,  1.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9014863463532665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}